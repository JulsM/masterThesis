{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load raceTimePredictor.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "import math as math\n",
    "import os, shutil\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "class RaceTimePredictor:\n",
    "\t\n",
    "\tdef __init__(self, FLAGS={}):\n",
    "\n",
    "\n",
    "\t\tself.FLAGS = {'learning_rate': 0.01,\n",
    "\t\t\t\t\t\t'training_steps': 40000,\n",
    "\t\t\t\t\t\t'batch_size': 128,\n",
    "\t\t\t\t\t\t'model_path': \"tf_checkpoints/\",\n",
    "\t\t\t\t\t\t'data_path' : 'kmeans'}\n",
    "\t\tfor key in FLAGS:\n",
    "\t\t\tself.FLAGS[key] = FLAGS[key]\n",
    "\n",
    "\t\tself.pathDict = {'races' : \"../output/raceFeatures.csv\",\n",
    "\t\t\t\t\t'kmeans': \"../output/trainFeatures.csv\",\n",
    "\t\t\t\t\t'all': \"../output/activitiesFeatures.csv\",\n",
    "\t\t\t\t\t'set' : \"../output/activitySetFeatures.csv\",\n",
    "\t\t\t\t\t'pred' : \"../output/predictions.csv\"}\n",
    "\t\t\n",
    "\t\tself.FEATURE_PATH = self.pathDict[self.FLAGS['data_path']]\n",
    "\t\tself.PRED_PATH = self.pathDict['pred']\n",
    "\t\tself.COLUMNS = [\"dist\", \"elev\", \"hilly\", \"cs\", \"atl\", \"ctl\", \"isRace\", \"avgVo2max\", \"time\", \"avgTrainPace\"]\n",
    "\t\tself.FEATURES = [\"dist\", \"elev\", \"hilly\", \"cs\", \"atl\", \"ctl\", \"isRace\", \"avgVo2max\", \"avgTrainPace\"]\n",
    "\n",
    "\t\tself.LABEL = \"time\"\n",
    "\n",
    "\t\tself.training_set = None\n",
    "\t\tself.test_set = None\n",
    "\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\n",
    "\n",
    "\tdef plotStatistics(self):\n",
    "\t\ttraining_set, test_set, prediction_set = loadData()\n",
    "\t\t# training_set, test_set, prediction_set = normalize(training_set, test_set, prediction_set)\n",
    "\t\tdataset = pd.concat([training_set, test_set])\n",
    "\t\t# training_set.hist()\n",
    "\n",
    "\t\t# dataset.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
    "\n",
    "\t\t# pd.plotting.scatter_matrix(dataset)\n",
    "\n",
    "\t\tcax = plt.matshow(dataset.corr(), vmin=-1, vmax=1)\n",
    "\t\tplt.colorbar(cax)\n",
    "\t\tlocs, labs = plt.xticks()\n",
    "\t\tplt.xticks(np.arange(len(COLUMNS)), COLUMNS)\n",
    "\t\tplt.yticks(np.arange(len(COLUMNS)), COLUMNS)\n",
    "\n",
    "\t\t# plt.scatter(dataset['dist'], dataset['CS'])\n",
    "\t\tplt.show()\n",
    "\n",
    "\tdef clearOldFiles(self):\n",
    "\t\tfilelist = [ f for f in os.listdir(self.FLAGS['model_path'])]\n",
    "\t\tfor f in filelist:\n",
    "\t\t\t# os.chmod(os.path.join(self.FLAGS['model_path'], f), 777)\n",
    "\t\t\tshutil.rmtree(os.path.join(self.FLAGS['model_path'], f))\n",
    "\t\t# if tf.gfile.Exists(self.FLAGS['model_path']):\n",
    "\t #   \t\ttf.gfile.DeleteRecursively(self.FLAGS['model_path']) \n",
    "\n",
    "\tdef normalize(self, data):\n",
    "\t\t# mean, std = train[FEATURES].mean(axis=0), train[FEATURES].std(axis=0, ddof=0)\n",
    "\t\t\n",
    "\t\tdata[self.FEATURES] = self.std_scaler.transform(data[self.FEATURES])\n",
    "\t\t# print(data)\n",
    "\t\treturn data\n",
    "\n",
    "\n",
    "\t\n",
    "\tdef loadTrainData(self):\n",
    "\t\ttrain_data = pd.read_csv(self.FEATURE_PATH, skipinitialspace=True, skiprows=1, names=self.COLUMNS)\n",
    "\t\ttrain_data = pd.DataFrame(train_data, columns=self.COLUMNS)\n",
    "\n",
    "\t\treturn train_data\n",
    "\n",
    "\tdef splitKFold(self, k, i):\n",
    "\t\t# print(self.train_data)\n",
    "\t\traces = self.train_data[self.train_data.isRace == 1]\n",
    "\t\tnoRaces = pd.DataFrame(self.train_data[self.train_data.isRace == -1], columns=self.COLUMNS)\n",
    "\t\tfoldLen = int(len(races) / k)\n",
    "\t\tstart = i * foldLen\n",
    "\t\tif i + 1 == k:\n",
    "\t\t\tend = len(races)\n",
    "\t\telse:\n",
    "\t\t\tend = (i + 1) * foldLen\n",
    "\t\t# print('len races: ', len(races))\n",
    "\t\t# print(start, end)\n",
    "\t\t# print(races)\n",
    "\t\ttest = races[start:end]\n",
    "\t\ttrain = races[0:start]\n",
    "\t\ttrain = train.append(races[end:])\n",
    "\t\t\n",
    "\t\tself.test_set = pd.DataFrame(test, columns=self.COLUMNS).reset_index(drop=True)\n",
    "\t\tself.training_set = noRaces.append(train).reset_index(drop=True)\n",
    "\t\t# print(self.training_set, self.test_set)\n",
    "\t\tprint('train size: ',len(self.training_set), ' test size: ', len(self.test_set))\n",
    "\n",
    "\n",
    "\n",
    "\tdef get_input_fn(self, data_set, num_epochs=None, shuffle=True):\n",
    "\t\t\treturn tf.estimator.inputs.pandas_input_fn(x=pd.DataFrame({k: data_set[k].values for k in self.FEATURES}), \n",
    "\t\t  \t\ty = pd.Series(data_set[self.LABEL].values), batch_size=self.FLAGS['batch_size'], num_epochs=num_epochs, shuffle=shuffle)\n",
    "\n",
    "\n",
    "\n",
    "\tdef model_fn(self, features, labels, mode, params):\n",
    "\t \n",
    "\n",
    "\t\t# Connect the first hidden layer to input layer\n",
    "\t\tfeature_cols = [tf.feature_column.numeric_column(k) for k in self.FEATURES]\n",
    "\t\tinput_layer = tf.feature_column.input_layer(features=features, feature_columns=feature_cols)\n",
    "\n",
    "\n",
    "\t\t# Connect the first hidden layer to second hidden layer with relu\n",
    "\t\thidden_layer = tf.layers.dense(input_layer, 10, activation=tf.nn.relu, \n",
    "\t\t\tkernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale_l1=1.0, scale_l2=1.0), name='hidden_1')\n",
    "\n",
    "\t\th1_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'hidden_1')\n",
    "\t\ttf.summary.histogram('kernel_1', h1_vars[0])\n",
    "\t\ttf.summary.histogram('bias_1', h1_vars[1])\n",
    "\t\ttf.summary.histogram('activation_1', hidden_layer)\n",
    "\n",
    "\t\tif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\t\t\thidden_layer = tf.layers.dropout(hidden_layer, rate=0.3, name='dropout_1')\n",
    "\t\t\ttf.summary.scalar('dropout_1', tf.nn.zero_fraction(hidden_layer))\n",
    "\n",
    "\n",
    "\n",
    "\t\t# Connect the second hidden layer to first hidden layer with relu\n",
    "\t\thidden_layer = tf.layers.dense(hidden_layer, 10, activation=tf.nn.relu, \n",
    "\t\t\tkernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale_l1=1.0, scale_l2=1.0), name='hidden_2')\n",
    "\n",
    "\t\th2_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'hidden_2')\n",
    "\t\ttf.summary.histogram('kernel_2', h2_vars[0])\n",
    "\t\ttf.summary.histogram('bias_2', h2_vars[1])\n",
    "\t\ttf.summary.histogram('activation_2', hidden_layer)\n",
    "\n",
    "\t\tif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\t\t\thidden_layer = tf.layers.dropout(hidden_layer, rate=0.3, name='dropout_2')\n",
    "\t\t\ttf.summary.scalar('dropout_2', tf.nn.zero_fraction(hidden_layer))\n",
    "\n",
    "\n",
    "\n",
    "\t\t# Connect the output layer to second hidden layer (no activation fn)\n",
    "\t\toutput_layer = tf.layers.dense(hidden_layer, 1, name='output')\n",
    "\n",
    "\t\t# Reshape output layer to 1-dim Tensor to return predictions\n",
    "\t\tpredictions = tf.reshape(output_layer, [-1])\n",
    "\n",
    "\t\t# Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "\t\tif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\t\t\treturn tf.estimator.EstimatorSpec(mode=mode,predictions={self.LABEL: predictions})\n",
    "\n",
    "\n",
    "\t\t# Calculate loss using mean squared error\n",
    "\t\tloss = tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "\t\treg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "\t\tloss = tf.add_n([loss] + reg_losses)\n",
    "\n",
    "\t\t\n",
    "\t\ttf.summary.scalar(\"reg_loss\", reg_losses[0])\n",
    "\t\ttf.summary.scalar(\"train_error\", loss)\n",
    "\n",
    "\n",
    "\n",
    "\t\toptimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "\t\ttrain_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "\t\talpha_t = optimizer._lr * tf.sqrt(1-optimizer._beta2_power) / (1-optimizer._beta1_power)\n",
    "\t\ttf.summary.scalar(\"learning_rate\", alpha_t)\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\t# Calculate root mean squared error as additional eval metric\n",
    "\t\teval_metric_ops = {\n",
    "\t\t  \"rmse\": tf.metrics.root_mean_squared_error(tf.cast(labels, tf.float64), tf.cast(predictions, tf.float64)),\n",
    "\t\t  \"r\" : tf.contrib.metrics.streaming_pearson_correlation(tf.cast(predictions, tf.float32), tf.cast(labels, tf.float32))\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t# Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n",
    "\t\treturn tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "\t\treturn EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)\n",
    "\n",
    "\n",
    "\tdef trainPredictor(self):\n",
    "\t\ttrain_input_fn = self.get_input_fn(self.training_set, num_epochs=None, shuffle=True)\n",
    "\n",
    "\t\t# Train\n",
    "\t\tself.estimator.train(input_fn=train_input_fn, steps=self.FLAGS['training_steps'])\n",
    "\n",
    "\n",
    "\tdef evaluatePredictor(self):\n",
    "\t\t# Score accuracy\n",
    "\t\ttest_input_fn = self.get_input_fn(self.test_set, num_epochs=1, shuffle=False)\n",
    "\t\tev = self.estimator.evaluate(input_fn=test_input_fn)\n",
    "\t\tprint(\"Loss: %s\" % ev['loss'])\n",
    "\t\tprint(\"Root Mean Squared Error: %s\\n\" % ev[\"rmse\"])\n",
    "\t\t# print(\"R: %s\" % ev[\"r\"])\n",
    "\t\treturn ev\n",
    "\n",
    "\n",
    "\tdef predictTimes(self):\n",
    "\t\tprint('\\nPredictions\\n')\n",
    "\t\tpred_data = pd.read_csv(self.PRED_PATH, skipinitialspace=True, skiprows=1, names=self.COLUMNS)\n",
    "\t\tprediction_set = pd.DataFrame(pred_data, columns=self.COLUMNS)\n",
    "\t\tprint(prediction_set)\n",
    "\t\tprediction_set = self.normalize(prediction_set)\n",
    "\t\t# prediction_set = pd.DataFrame([(21000, 400, 0.5, 1.8, 44, 45, 1, 43, 90,3.448)], columns=COLUMNS)\n",
    "\t\t# Print out predictions\n",
    "\n",
    "\t\tpredict_input_fn = self.get_input_fn(prediction_set, num_epochs=1, shuffle=False)\n",
    "\t\tpredictions = self.estimator.predict(input_fn=predict_input_fn)\n",
    "\t\tpred = list()\n",
    "\t\t\n",
    "\t\tfor i, p in enumerate(predictions):\n",
    "\t\t\tprint(\"Predicted time %s: %s\" % (i, round(p[self.LABEL], 2)))\n",
    "\t\t\tpred.append(p[self.LABEL])\n",
    "\t\t\tprint(\"+/- Seconds: %s\" % (round((p[self.LABEL] - prediction_set[self.LABEL][i]) * 60, 2)))\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\tdef trainCrossValidated(self, kfold):\n",
    "\t\tprint('Load Data\\n')\n",
    "\t\tself.train_data = self.loadTrainData()\n",
    "\t\tself.clearOldFiles()\n",
    "\t\tkfoldLosses = []\n",
    "\t\tkfoldRmse = []\n",
    "\t\tprint('Start training\\n')\n",
    "\t\tfor i in range(kfold):\n",
    "\t\t\tmodel_params = {\"learning_rate\": self.FLAGS['learning_rate']}\n",
    "\t\t\tself.estimator = tf.estimator.Estimator(model_fn=self.model_fn, params=model_params, model_dir=self.FLAGS['model_path']+'temp_'+str(i))\n",
    "\n",
    "\t\t\tself.splitKFold(kfold, i)\n",
    "\t\t\tself.std_scaler = preprocessing.StandardScaler().fit(self.training_set[self.FEATURES])\n",
    "\t\t\tself.training_set = self.normalize(self.training_set)\n",
    "\t\t\tself.test_set = self.normalize(self.test_set)\n",
    "\t\t\t\n",
    "\t\t\tself.trainPredictor()\n",
    "\t\t\tmetrics = self.evaluatePredictor()\n",
    "\t\t\tkfoldLosses.append(metrics['loss'])\n",
    "\t\t\tkfoldRmse.append(metrics['rmse'])\n",
    "\n",
    "\t\tprint(\"\\nMean loss for %s-fold cross validation: %s\" % (kfold, np.mean(kfoldLosses)))\n",
    "\t\tprint(\"Mean RMSE for %s-fold cross validation: %s\" % (kfold, np.mean(kfoldRmse)))\n",
    "\t\tself.predictTimes()\n",
    "\n",
    "\n",
    "\tdef trainStandard(self):\n",
    "\t\tprint('Load Data\\n')\n",
    "\t\tself.training_set = self.loadTrainData()\n",
    "\t\tself.clearOldFiles()\n",
    "\n",
    "\t\tmodel_params = {\"learning_rate\": self.FLAGS['learning_rate']}\t\t\n",
    "\t\tself.estimator = tf.estimator.Estimator(model_fn=self.model_fn, params=model_params, model_dir=self.FLAGS['model_path']+'temp')\n",
    "\n",
    "\t\tself.std_scaler = preprocessing.StandardScaler().fit(self.training_set[self.FEATURES])\n",
    "\t\tself.training_set = self.normalize(self.training_set)\n",
    "\n",
    "\t\ttest_data = pd.read_csv(self.PRED_PATH, skipinitialspace=True, skiprows=1, names=self.COLUMNS)\n",
    "\t\ttest_set = pd.DataFrame(test_data, columns=self.COLUMNS)\n",
    "\t\tself.test_set = self.normalize(test_set)\n",
    "\t\tprint('train size: ',len(self.training_set), ' test size: ', len(self.test_set))\n",
    "\n",
    "\t\tprint('Start training\\n')\n",
    "\t\tself.trainPredictor()\n",
    "\n",
    "\t\tself.evaluatePredictor()\n",
    "\n",
    "\t\tself.predictTimes()\n",
    "\n",
    "\tdef trainWithPretraining(self, kfold):\n",
    "\t\tprint('Pre-train Set\\n')\n",
    "\t\tself.FEATURE_PATH = self.pathDict['set']\n",
    "\t\tself.training_set = self.loadTrainData()\n",
    "\t\tprint('train size: ',len(self.training_set))\n",
    "\t\tself.clearOldFiles()\n",
    "\n",
    "\t\tmodel_params = {\"learning_rate\": self.FLAGS['learning_rate']}\n",
    "\t\tself.estimator = tf.estimator.Estimator(model_fn=self.model_fn, params=model_params, model_dir=self.FLAGS['model_path']+'pretrain')\n",
    "\t\tself.std_scaler = preprocessing.StandardScaler().fit(self.training_set[self.FEATURES])\n",
    "\t\tself.training_set = self.normalize(self.training_set)\n",
    "\t\tprint('Start training\\n')\n",
    "\t\tself.trainPredictor()\n",
    "\n",
    "\t\tprint('Pre-train kmeans\\n')\n",
    "\t\tself.FEATURE_PATH = self.pathDict['kmeans']\n",
    "\t\tself.training_set = self.loadTrainData()\n",
    "\t\tprint('train size: ',len(self.training_set))\n",
    "\t\tself.std_scaler = preprocessing.StandardScaler().fit(self.training_set[self.FEATURES])\n",
    "\t\tself.training_set = self.normalize(self.training_set)\n",
    "\t\tprint('Start training\\n')\n",
    "\t\tself.trainPredictor()\n",
    "\n",
    "\t\t### copy pre-trained model to kfold folders\n",
    "\t\tfor i in range(kfold):\n",
    "\t\t\tsrc = self.FLAGS['model_path']+'pretrain'\n",
    "\t\t\tdst = self.FLAGS['model_path']+'temp_'+str(i)\n",
    "\t\t\tshutil.copytree(src, dst)\n",
    "\n",
    "\t\t\n",
    "\t\tprint('Train races\\n')\n",
    "\t\tself.FEATURE_PATH = self.pathDict['races']\n",
    "\t\tself.train_data = self.loadTrainData()\n",
    "\t\tkfoldLosses = []\n",
    "\t\tkfoldRmse = []\n",
    "\t\tprint('Start training\\n')\n",
    "\t\tfor i in range(kfold):\n",
    "\t\t\tmodel_params = {\"learning_rate\": self.FLAGS['learning_rate']}\n",
    "\t\t\tself.estimator = tf.estimator.Estimator(model_fn=self.model_fn, params=model_params, model_dir=self.FLAGS['model_path']+'temp_'+str(i))\n",
    "\n",
    "\t\t\tself.splitKFold(kfold, i)\n",
    "\t\t\tself.std_scaler = preprocessing.StandardScaler().fit(self.training_set[self.FEATURES])\n",
    "\t\t\tself.training_set = self.normalize(self.training_set)\n",
    "\t\t\tself.test_set = self.normalize(self.test_set)\n",
    "\t\t\t\n",
    "\t\t\tself.trainPredictor()\n",
    "\t\t\tmetrics = self.evaluatePredictor()\n",
    "\t\t\tkfoldLosses.append(metrics['loss'])\n",
    "\t\t\tkfoldRmse.append(metrics['rmse'])\n",
    "\n",
    "\t\tprint(\"\\nMean loss for %s-fold cross validation: %s\" % (kfold, np.mean(kfoldLosses)))\n",
    "\t\tprint(\"Mean RMSE for %s-fold cross validation: %s\" % (kfold, np.mean(kfoldRmse)))\n",
    "\t\tself.predictTimes()\n",
    "\t\t\n",
    "def main(unused_argv):\n",
    "\tpredictor = RaceTimePredictor({'training_steps': 40000, 'data_path' : 'all'})\n",
    "\tpredictor.trainWithPretraining(4)\n",
    "\t# predictor.trainCrossValidated(4)\n",
    "\t# predictor.trainStandard()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Races with 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "\n",
      "Start training\n",
      "\n",
      "train size:  13  test size:  4\n",
      "Loss: 28.494\n",
      "Root Mean Squared Error: 5.16616\n",
      "\n",
      "train size:  13  test size:  4\n",
      "Loss: 2.83178\n",
      "Root Mean Squared Error: 0.751062\n",
      "\n",
      "train size:  13  test size:  4\n",
      "Loss: 41.8187\n",
      "Root Mean Squared Error: 6.31373\n",
      "\n",
      "train size:  12  test size:  5\n",
      "Loss: 6.6345\n",
      "Root Mean Squared Error: 2.21815\n",
      "\n",
      "\n",
      "Mean loss for 4-fold cross validation: 19.9447\n",
      "Mean RMSE for 4-fold cross validation: 3.61228\n",
      "\n",
      "Predictions\n",
      "\n",
      "     dist  elev  hilly   cs  atl  ctl  isRace  avgVo2max   time  avgTrainPace\n",
      "0    5000     0    0.0  0.0   30   45       1       43.5   17.5      3.448707\n",
      "1    5000    70    0.1  0.2   30   45       1       43.5   19.0      3.448707\n",
      "2    5000   150    0.3  1.5   30   45       1       43.5   22.0      3.448707\n",
      "3   10000     0    0.0  0.0   30   45       1       43.5   36.5      3.448707\n",
      "4   10000    70    0.3  0.5   30   45       1       43.5   39.0      3.448707\n",
      "5   10000   150    0.5  1.5   30   45       1       43.5   41.0      3.448707\n",
      "6   21097     0    0.0  0.0   30   45       1       43.5   79.0      3.448707\n",
      "7   21097    70    0.3  0.5   30   45       1       43.5   81.0      3.448707\n",
      "8   21097   150    0.4  1.5   30   50       1       43.5   85.0      3.448707\n",
      "9   42195     0    0.0  0.0   30   50       1       43.5  170.0      3.448707\n",
      "10  42195   150    0.5  1.0   30   50       1       43.5  185.0      3.448707\n",
      "Predicted time 0: 18.04\n",
      "+/- Seconds: 32.23\n",
      "Predicted time 1: 19.07\n",
      "+/- Seconds: 4.43\n",
      "Predicted time 2: 23.67\n",
      "+/- Seconds: 100.01\n",
      "Predicted time 3: 38.29\n",
      "+/- Seconds: 107.56\n",
      "Predicted time 4: 39.51\n",
      "+/- Seconds: 30.7\n",
      "Predicted time 5: 43.05\n",
      "+/- Seconds: 122.71\n",
      "Predicted time 6: 83.25\n",
      "+/- Seconds: 254.87\n",
      "Predicted time 7: 84.47\n",
      "+/- Seconds: 208.01\n",
      "Predicted time 8: 88.83\n",
      "+/- Seconds: 229.91\n",
      "Predicted time 9: 169.11\n",
      "+/- Seconds: -53.34\n",
      "Predicted time 10: 172.1\n",
      "+/- Seconds: -774.15\n"
     ]
    }
   ],
   "source": [
    "%run raceTimePredictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans with 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "\n",
      "Start training\n",
      "\n",
      "train size:  62  test size:  4\n",
      "Loss: 4.54042\n",
      "Root Mean Squared Error: 1.17342\n",
      "\n",
      "train size:  62  test size:  4\n",
      "Loss: 3.96096\n",
      "Root Mean Squared Error: 0.88721\n",
      "\n",
      "train size:  62  test size:  4\n",
      "Loss: 6.23742\n",
      "Root Mean Squared Error: 1.74686\n",
      "\n",
      "train size:  61  test size:  5\n",
      "Loss: 4.53395\n",
      "Root Mean Squared Error: 1.20316\n",
      "\n",
      "\n",
      "Mean loss for 4-fold cross validation: 4.81819\n",
      "Mean RMSE for 4-fold cross validation: 1.25266\n",
      "\n",
      "Predictions\n",
      "\n",
      "     dist  elev  hilly   cs  atl  ctl  isRace  avgVo2max   time  avgTrainPace\n",
      "0    5000     0    0.0  0.0   30   45       1       43.5   17.5      3.448707\n",
      "1    5000    70    0.1  0.2   30   45       1       43.5   19.0      3.448707\n",
      "2    5000   150    0.3  1.5   30   45       1       43.5   22.0      3.448707\n",
      "3   10000     0    0.0  0.0   30   45       1       43.5   36.5      3.448707\n",
      "4   10000    70    0.3  0.5   30   45       1       43.5   39.0      3.448707\n",
      "5   10000   150    0.5  1.5   30   45       1       43.5   41.0      3.448707\n",
      "6   21097     0    0.0  0.0   30   45       1       43.5   79.0      3.448707\n",
      "7   21097    70    0.3  0.5   30   45       1       43.5   81.0      3.448707\n",
      "8   21097   150    0.4  1.5   30   50       1       43.5   85.0      3.448707\n",
      "9   42195     0    0.0  0.0   30   50       1       43.5  170.0      3.448707\n",
      "10  42195   150    0.5  1.0   30   50       1       43.5  185.0      3.448707\n",
      "Predicted time 0: 16.98\n",
      "+/- Seconds: -31.15\n",
      "Predicted time 1: 18.99\n",
      "+/- Seconds: -0.75\n",
      "Predicted time 2: 23.43\n",
      "+/- Seconds: 86.03\n",
      "Predicted time 3: 36.94\n",
      "+/- Seconds: 26.18\n",
      "Predicted time 4: 38.49\n",
      "+/- Seconds: -30.3\n",
      "Predicted time 5: 42.2\n",
      "+/- Seconds: 71.71\n",
      "Predicted time 6: 81.23\n",
      "+/- Seconds: 133.53\n",
      "Predicted time 7: 82.78\n",
      "+/- Seconds: 107.05\n",
      "Predicted time 8: 87.6\n",
      "+/- Seconds: 155.86\n",
      "Predicted time 9: 165.95\n",
      "+/- Seconds: -243.25\n",
      "Predicted time 10: 169.96\n",
      "+/- Seconds: -902.32\n"
     ]
    }
   ],
   "source": [
    "%run raceTimePredictor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athletes activities with 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "\n",
      "Start training\n",
      "\n",
      "train size:  155  test size:  4\n",
      "Loss: 4.42331\n",
      "Root Mean Squared Error: 0.620158\n",
      "\n",
      "train size:  155  test size:  4\n",
      "Loss: 12.4052\n",
      "Root Mean Squared Error: 2.88841\n",
      "\n",
      "train size:  155  test size:  4\n",
      "Loss: 10.9101\n",
      "Root Mean Squared Error: 2.62405\n",
      "\n",
      "train size:  154  test size:  5\n",
      "Loss: 11.322\n",
      "Root Mean Squared Error: 2.72118\n",
      "\n",
      "\n",
      "Mean loss for 4-fold cross validation: 9.76514\n",
      "Mean RMSE for 4-fold cross validation: 2.21345\n",
      "\n",
      "Predictions\n",
      "\n",
      "     dist  elev  hilly   cs  atl  ctl  isRace  avgVo2max   time  avgTrainPace\n",
      "0    5000     0    0.0  0.0   30   45       1       43.5   17.5      3.448707\n",
      "1    5000    70    0.1  0.2   30   45       1       43.5   19.0      3.448707\n",
      "2    5000   150    0.3  1.5   30   45       1       43.5   22.0      3.448707\n",
      "3   10000     0    0.0  0.0   30   45       1       43.5   36.5      3.448707\n",
      "4   10000    70    0.3  0.5   30   45       1       43.5   39.0      3.448707\n",
      "5   10000   150    0.5  1.5   30   45       1       43.5   41.0      3.448707\n",
      "6   21097     0    0.0  0.0   30   45       1       43.5   79.0      3.448707\n",
      "7   21097    70    0.3  0.5   30   45       1       43.5   81.0      3.448707\n",
      "8   21097   150    0.4  1.5   30   50       1       43.5   85.0      3.448707\n",
      "9   42195     0    0.0  0.0   30   50       1       43.5  170.0      3.448707\n",
      "10  42195   150    0.5  1.0   30   50       1       43.5  185.0      3.448707\n",
      "Predicted time 0: 18.15\n",
      "+/- Seconds: 38.86\n",
      "Predicted time 1: 21.75\n",
      "+/- Seconds: 165.11\n",
      "Predicted time 2: 25.54\n",
      "+/- Seconds: 212.2\n",
      "Predicted time 3: 37.1\n",
      "+/- Seconds: 36.0\n",
      "Predicted time 4: 37.92\n",
      "+/- Seconds: -65.02\n",
      "Predicted time 5: 41.43\n",
      "+/- Seconds: 25.63\n",
      "Predicted time 6: 79.16\n",
      "+/- Seconds: 9.79\n",
      "Predicted time 7: 79.98\n",
      "+/- Seconds: -61.24\n",
      "Predicted time 8: 84.99\n",
      "+/- Seconds: -0.52\n",
      "Predicted time 9: 159.11\n",
      "+/- Seconds: -653.69\n",
      "Predicted time 10: 162.98\n",
      "+/- Seconds: -1321.44\n"
     ]
    }
   ],
   "source": [
    "%run raceTimePredictor.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
